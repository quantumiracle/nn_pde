{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import time\n",
    "from itertools import product, combinations\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from plotting import newfig, savefig\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import rc\n",
    "\n",
    "np.random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(X_star, u_star, index):\n",
    "    \n",
    "    lb = X_star.min(0)\n",
    "    ub = X_star.max(0)\n",
    "    nn = 200\n",
    "    x = np.linspace(lb[0], ub[0], nn)\n",
    "    y = np.linspace(lb[1], ub[1], nn)\n",
    "    X, Y = np.meshgrid(x,y)\n",
    "    \n",
    "    U_star = griddata(X_star, u_star.flatten(), (X, Y), method='cubic')\n",
    "    \n",
    "    plt.figure(index)\n",
    "    plt.pcolor(X,Y,U_star, cmap = 'jet')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "def axisEqual3D(ax):\n",
    "    extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in 'xyz'])\n",
    "    sz = extents[:,1] - extents[:,0]\n",
    "    centers = np.mean(extents, axis=1)\n",
    "    maxsize = max(abs(sz))\n",
    "    r = maxsize/4\n",
    "    for ctr, dim in zip(centers, 'xyz'):\n",
    "        getattr(ax, 'set_{}lim'.format(dim))(ctr - r, ctr + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu102\n",
      "PhysicsInformedNN(\n",
      "  (input_layer): Linear(in_features=3, out_features=20, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (5): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (7): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  (ouput_layer): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "torch.Size([5000]) torch.Size([5000, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.8779, grad_fn=<CopyBackwards>)\n",
      "tensor(31.7202, grad_fn=<CopyBackwards>)\n",
      "tensor(93.4944, grad_fn=<CopyBackwards>)\n",
      "tensor(403.3717, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "# for NS equation\n",
    "from train import PhysicsInformedNN\n",
    "from torch.autograd import grad\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(torch.__version__)\n",
    "data = scipy.io.loadmat('./data/cylinder_nektar_wake.mat')\n",
    "U_star = data['U_star'] # N x 2 x T; full data of (u, v) at all x, y, t\n",
    "P_star = data['p_star'] # N x T; full data of p at all x, y, t\n",
    "t_star = data['t'] # T x 1; t corrdinates of the full data\n",
    "X_star = data['X_star'] # N x 2; (x,y) coordinates of the full data\n",
    "\n",
    "N = X_star.shape[0] # N=5000; size of the full data at a fixed t\n",
    "T = t_star.shape[0] # T=200; size of the full data at a fixed x,y\n",
    "\n",
    "# Rearrange Data \n",
    "XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
    "YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
    "TT = np.tile(t_star, (1,N)).T # N x T\n",
    "\n",
    "UU = U_star[:,0,:] # N x T\n",
    "VV = U_star[:,1,:] # N x T\n",
    "PP = P_star # N x T\n",
    "\n",
    "x = XX.flatten()[:,None] # NT x 1\n",
    "y = YY.flatten()[:,None] # NT x 1\n",
    "t = TT.flatten()[:,None] # NT x 1\n",
    "\n",
    "u = UU.flatten()[:,None] # NT x 1\n",
    "v = VV.flatten()[:,None] # NT x 1\n",
    "p = PP.flatten()[:,None] # NT x 1\n",
    "\n",
    "# Training Data   \n",
    "N_train = 5000 \n",
    "idx = np.random.choice(N*T, N_train, replace=False) # Generate a random sample from np.arange(N*T) of size N_train without replacement\n",
    "x_train = x[idx,:]\n",
    "y_train = y[idx,:]\n",
    "t_train = t[idx,:]\n",
    "u_train = u[idx,:]\n",
    "v_train = v[idx,:]\n",
    "# print(np.max(u_train), np.min(u_train), np.max(v_train),  np.min(v_train))\n",
    "\n",
    "# Load Model\n",
    "xyt_train = np.concatenate([x, y, t], 1)\n",
    "pinn = PhysicsInformedNN(xyt_train, u_train, v_train, layers=8, device=device).to(device) \n",
    "print(pinn)\n",
    "path = './model/20220424_1600'\n",
    "load_model(pinn, path, device)\n",
    "\n",
    "\n",
    "# Test Data\n",
    "snap = np.array([100])\n",
    "x_star = X_star[:,0:1]\n",
    "y_star = X_star[:,1:2]\n",
    "t_star = TT[:,snap]\n",
    "\n",
    "u_star = U_star[:,0,snap]\n",
    "v_star = U_star[:,1,snap]\n",
    "p_star = P_star[:,snap]\n",
    "\n",
    "xyt_star = np.concatenate([x_star, y_star, t_star], 1)\n",
    "\n",
    "# Make prediction with trained model\n",
    "xyt = torch.FloatTensor(xyt_star)\n",
    "xyt.requires_grad=True \n",
    "u_pred, v_pred, p_pred, _, _ = pinn.forward(xyt)\n",
    "# u_pred = u_pred.detach().cpu().numpy()\n",
    "# v_pred = v_pred.detach().cpu().numpy()\n",
    "# p_pred = p_pred.detach().cpu().numpy()\n",
    "\n",
    "lambda_1_value = pinn.lambda_1\n",
    "lambda_2_value = pinn.lambda_2\n",
    "\n",
    "Du = grad(u_pred, xyt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_x = Du[0][:,0]\n",
    "Du_x = grad(u_x, xyt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_xx = Du_x[0][:,0]\n",
    "Du_xx = grad(u_xx, xyt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_xxx = Du_xx[0][:,0]\n",
    "Du_xxx = grad(u_xxx, xyt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_xxxx = Du_xxx[0][:,0]\n",
    "\n",
    "print(torch.linalg.norm(u_x, 2))\n",
    "print(torch.linalg.norm(u_xx, 2))\n",
    "print(torch.linalg.norm(u_xxx, 2))\n",
    "print(torch.linalg.norm(u_xxxx, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicsInformedNN(\n",
      "  (input_layer): Linear(in_features=2, out_features=20, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (5): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (7): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      "  (ouput_layer): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "torch.Size([2]) torch.Size([2, 2])\n",
      "tensor(4.2734, grad_fn=<CopyBackwards>)\n",
      "tensor(11.5721, grad_fn=<CopyBackwards>)\n",
      "tensor(147.6738, grad_fn=<CopyBackwards>) tensor([121.8490, -83.4289], grad_fn=<SelectBackward0>)\n",
      "tensor(334.2044, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantumiracle/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "# for heat equation\n",
    "from train_heat import PhysicsInformedNN, load_data\n",
    "from torch.autograd import grad\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "collc_xt, collc_z, data_xt, data_z, test_xt, test_z = load_data(device)\n",
    "\n",
    "optim_method = \"adam\"\n",
    "layers = 8\n",
    "nIter = 50000  # original niter is 200000\n",
    "lr = 0.001\n",
    "batch = 10000\n",
    "\n",
    "# Load Model\n",
    "pinn = PhysicsInformedNN(data_xt, data_z, layers, device, optim_method, lr).to(device) \n",
    "print(pinn)\n",
    "path = './model/20220426_1719'\n",
    "load_model(pinn, path, device)\n",
    "\n",
    "# Make prediction with trained model\n",
    "test_xt = test_xt[:2]\n",
    "u_pred, _ = pinn.forward(test_xt)\n",
    "u_pred = u_pred.squeeze()\n",
    "print(u_pred.shape, test_xt.shape)\n",
    "\n",
    "Du = grad(u_pred, test_xt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_x = Du[0][:,0]\n",
    "Du_x = grad(u_x, test_xt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_xx = Du_x[0][:,0]\n",
    "Du_xx = grad(u_xx, test_xt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_xxx = Du_xx[0][:,0]\n",
    "Du_xxx = grad(u_xxx, test_xt, grad_outputs=torch.ones_like(torch.Tensor(u_pred)), create_graph=True, retain_graph=True)\n",
    "u_xxxx = Du_xxx[0][:,0]\n",
    "\n",
    "print(torch.linalg.norm(u_x, 2))\n",
    "print(torch.linalg.norm(u_xx, 2))\n",
    "print(torch.linalg.norm(u_xxx, 2))\n",
    "print(torch.linalg.norm(u_xxxx, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28c6861e59928cb790236f7047915368f37afc12f670e78fd0101a6f825a02b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('x': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
